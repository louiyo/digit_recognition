{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import *\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(\n",
    "    1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_norm = (train_input - torch.min(train_input)) / (torch.max(train_input))\n",
    "test_input_norm = (test_input - torch.min(train_input)) / (torch.max(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f88c197c10>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input_norm[550][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_err_digit_recog(model, test_input, test_classes, batches = False):\n",
    "\n",
    "    correct_count_digit, all_count_digit = 0, 0\n",
    "    correct_count_equal, all_count_equal = 0, 0\n",
    "    \n",
    "    if not batches:\n",
    "    \n",
    "    \n",
    "        for img, label, target, i in zip(test_input, test_classes, \n",
    "                                                test_target, range(len(test_classes))):   \n",
    "            with torch.no_grad():\n",
    "                log_probs_digits, probs_equality = model(img)\n",
    "\n",
    "\n",
    "            probs = torch.exp(log_probs_digits)\n",
    "            _, preds = torch.max(probs,dim=1)\n",
    "            true_labels = label\n",
    "\n",
    "            for predicted, groundtruth in zip(preds, true_labels):\n",
    "                if(predicted == groundtruth):\n",
    "                    correct_count_digit += 1\n",
    "                all_count_digit += 1\n",
    "\n",
    "\n",
    "            if((torch.sigmoid(probs_equality) > 0.5 and target == 1) or \n",
    "                       (torch.sigmoid(probs_equality) <= 0.5 and target == 0)):\n",
    "                correct_count_equal += 1\n",
    "            all_count_equal +=1\n",
    "            \n",
    "            \n",
    "    else:\n",
    "\n",
    "        for i in range(0, len(test_input), mini_batch_size):\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                log_probs_digits, probs_equality = model(test_input.narrow(0, b, mini_batch_size))\n",
    "            probs = torch.exp(log_probs_digits)\n",
    "            _, preds = torch.max(probs,dim=2)\n",
    "            true_labels = test_classes.narrow(0, b, mini_batch_size)\n",
    "            targets = test_target.narrow(0, b, mini_batch_size)\n",
    "            \n",
    "            \n",
    "            \n",
    "            for predicted, groundtruth in zip(preds, true_labels):\n",
    "                if(predicted[0] == groundtruth[0]):\n",
    "                    correct_count_digit += 1\n",
    "                if(predicted[1] == groundtruth[1]):\n",
    "                    correct_count_digit += 1\n",
    "                all_count_digit += 2\n",
    "               \n",
    "            for prob_equality, target in zip(probs_equality.view(-1), targets):\n",
    "                if((torch.sigmoid(prob_equality) >= 0.5 and target == 1) or \n",
    "                           (torch.sigmoid(prob_equality) < 0.5 and target == 0)):\n",
    "                    correct_count_equal += 1\n",
    "                all_count_equal +=1\n",
    "            \n",
    "            \n",
    "        \n",
    "    print(\"Number Of Images Tested =\", all_count_digit)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count_digit/all_count_digit), '\\n\\n')\n",
    "    print(\"Number Of Inequalities tested =\", all_count_equal)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count_equal/all_count_equal))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35896\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(196, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "        self.fc5 = nn.Linear(10, 1)\n",
    "        self.fc6 = nn.Linear(2, 1)\n",
    "        \n",
    "        self.logsoft = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # INPUT IS A (2, 14, 14) TENSOR, OUTPUT IS (1)\n",
    "        x = self.fc0(x)\n",
    "        # (2, 196)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        output1 = self.logsoft(x)\n",
    "        #x = F.relu(self.fc5(torch.exp(x)))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = x.view(-1)\n",
    "        output2 = self.fc6(x)\n",
    "        #print(output2)\n",
    "        return output1, output2\n",
    "print(get_n_params(Net2()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51320"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net_convo(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convlayer1 = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, 3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2))\n",
    "        \n",
    "        self.convlayer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.lin1 = nn.Linear(3200, 10)\n",
    "        self.lin2 = nn.Linear(10, 1)\n",
    "        self.lin3 = nn.Linear(2, 1)\n",
    "        \n",
    "        self.logsoft = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.convlayer1(x)\n",
    "        x = self.convlayer2(x)\n",
    "        \n",
    "        x = x.view(25, 2, -1)\n",
    "        \n",
    "        # (25, 2, 3200)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        # (25, 2, 10)\n",
    "        output1 = self.logsoft(x)\n",
    "        \n",
    "        # (25, 2, 10)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        #print(x.size())\n",
    "        # (25, 2, 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # (25, 2)\n",
    "        output2 = self.lin3(x)\n",
    "        # (25, 1)\n",
    "        return output1, output2\n",
    "    \n",
    "get_n_params(Net_convo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches of (2, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 2.655381785571575\n",
      "\n",
      "Training Time = 2.0 seconds\n",
      "Epoch 2 - Training loss: 2.6402417824566364\n",
      "\n",
      "Training Time = 4.11 seconds\n",
      "Epoch 3 - Training loss: 2.620884198755026\n",
      "\n",
      "Training Time = 6.44 seconds\n",
      "Epoch 4 - Training loss: 2.5653105210363867\n",
      "\n",
      "Training Time = 8.64 seconds\n",
      "Epoch 5 - Training loss: 2.408268036738038\n",
      "\n",
      "Training Time = 10.84 seconds\n",
      "Epoch 6 - Training loss: 2.1597959524076433\n",
      "\n",
      "Training Time = 13.06 seconds\n",
      "Epoch 7 - Training loss: 1.940251943745534\n",
      "\n",
      "Training Time = 15.18 seconds\n",
      "Epoch 8 - Training loss: 1.7934659744183301\n",
      "\n",
      "Training Time = 17.28 seconds\n",
      "Epoch 9 - Training loss: 1.6739483309514325\n",
      "\n",
      "Training Time = 20.05 seconds\n",
      "Epoch 10 - Training loss: 1.5623120008763216\n",
      "\n",
      "Training Time = 22.59 seconds\n",
      "Epoch 11 - Training loss: 1.4736652182630496\n",
      "\n",
      "Training Time = 24.83 seconds\n",
      "Epoch 12 - Training loss: 1.3972670073473419\n",
      "\n",
      "Training Time = 26.95 seconds\n",
      "Epoch 13 - Training loss: 1.3491126243266045\n",
      "\n",
      "Training Time = 29.08 seconds\n",
      "Epoch 14 - Training loss: 1.315148753718473\n",
      "\n",
      "Training Time = 31.2 seconds\n",
      "Epoch 15 - Training loss: 1.2074917589589604\n",
      "\n",
      "Training Time = 33.66 seconds\n",
      "Epoch 16 - Training loss: 1.0447854056638535\n",
      "\n",
      "Training Time = 35.86 seconds\n",
      "Epoch 17 - Training loss: 0.8757728926639738\n",
      "\n",
      "Training Time = 37.93 seconds\n",
      "Epoch 18 - Training loss: 0.755421585077278\n",
      "\n",
      "Training Time = 40.55 seconds\n",
      "Epoch 19 - Training loss: 0.70346703719986\n",
      "\n",
      "Training Time = 42.83 seconds\n",
      "Epoch 20 - Training loss: 0.6611595136887254\n",
      "\n",
      "Training Time = 44.96 seconds\n",
      "Epoch 21 - Training loss: 0.5998911361507726\n",
      "\n",
      "Training Time = 46.92 seconds\n",
      "Epoch 22 - Training loss: 0.5665987494729675\n",
      "\n",
      "Training Time = 48.88 seconds\n",
      "Epoch 23 - Training loss: 0.5491604065940644\n",
      "\n",
      "Training Time = 50.85 seconds\n",
      "Epoch 24 - Training loss: 0.5112194129463198\n",
      "\n",
      "Training Time = 52.83 seconds\n",
      "Epoch 25 - Training loss: 0.48227820944915584\n",
      "\n",
      "Training Time = 54.82 seconds\n",
      "Number Of Images Tested = 2000\n",
      "\n",
      "Model Accuracy = 0.8585 \n",
      "\n",
      "\n",
      "Number Of Inequalities tested = 1000\n",
      "\n",
      "Model Accuracy = 0.809\n"
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "\n",
    "criterion1 = nn.NLLLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.8)\n",
    "time0 = time()\n",
    "epochs = 25\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i in range(len(train_input_norm)):\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        #optimizer_aux.zero_grad()\n",
    "        #print(torch.flatten(train_input_flat.narrow(0, b, mini_batch_size), 1, 2).size())\n",
    "\n",
    "        output1, output2 = model(train_input_norm[i])\n",
    "        loss1 = criterion1(output1, train_classes[i])\n",
    "        loss2 = criterion2(output2, train_target[i].reshape(1).to(torch.float32))\n",
    "        \n",
    "        w2 = 0.5\n",
    "\n",
    "        loss = loss1 + loss2 * w2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss += loss1.item() + loss2.item() * w2\n",
    "    print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(train_input)))\n",
    "    print(\"\\nTraining Time =\", round(time()-time0, 2), \"seconds\")\n",
    "    \n",
    "compute_err_digit_recog(model, test_input, test_classes, batches = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches of (b, 2, 14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.10479671617746353\n",
      "\n",
      "Training Time = 0.58 seconds\n",
      "Epoch 2 - Training loss: 0.08834011164903639\n",
      "\n",
      "Training Time = 0.64 seconds\n",
      "Epoch 3 - Training loss: 0.06949702562093737\n",
      "\n",
      "Training Time = 0.61 seconds\n",
      "Epoch 4 - Training loss: 0.054771576631069165\n",
      "\n",
      "Training Time = 0.59 seconds\n",
      "Epoch 5 - Training loss: 0.04590847432613373\n",
      "\n",
      "Training Time = 0.59 seconds\n",
      "Epoch 6 - Training loss: 0.040372676992416374\n",
      "\n",
      "Training Time = 0.6 seconds\n",
      "Epoch 7 - Training loss: 0.036176116609573365\n",
      "\n",
      "Training Time = 0.56 seconds\n",
      "Epoch 8 - Training loss: 0.033221518111228955\n",
      "\n",
      "Training Time = 0.7 seconds\n",
      "Epoch 9 - Training loss: 0.03077903589010239\n",
      "\n",
      "Training Time = 0.56 seconds\n",
      "Epoch 10 - Training loss: 0.028933690333366388\n",
      "\n",
      "Training Time = 0.57 seconds\n",
      "Epoch 11 - Training loss: 0.02747446174621582\n",
      "\n",
      "Training Time = 0.6 seconds\n",
      "Epoch 12 - Training loss: 0.02596698683500289\n",
      "\n",
      "Training Time = 0.54 seconds\n",
      "Epoch 13 - Training loss: 0.024961745882034304\n",
      "\n",
      "Training Time = 0.51 seconds\n",
      "Epoch 14 - Training loss: 0.023802358919382097\n",
      "\n",
      "Training Time = 0.64 seconds\n",
      "Epoch 15 - Training loss: 0.02296699297130108\n",
      "\n",
      "Training Time = 0.56 seconds\n",
      "Epoch 16 - Training loss: 0.021906113344430923\n",
      "\n",
      "Training Time = 0.52 seconds\n",
      "Epoch 17 - Training loss: 0.02130361058115959\n",
      "\n",
      "Training Time = 0.55 seconds\n",
      "Epoch 18 - Training loss: 0.020412007227540017\n",
      "\n",
      "Training Time = 0.56 seconds\n",
      "Epoch 19 - Training loss: 0.019802760866284366\n",
      "\n",
      "Training Time = 0.63 seconds\n",
      "Epoch 20 - Training loss: 0.018979248422384267\n",
      "\n",
      "Training Time = 0.52 seconds\n",
      "Epoch 21 - Training loss: 0.01865296387374402\n",
      "\n",
      "Training Time = 0.54 seconds\n",
      "Epoch 22 - Training loss: 0.018039231497049335\n",
      "\n",
      "Training Time = 0.66 seconds\n",
      "Epoch 23 - Training loss: 0.017175864131748677\n",
      "\n",
      "Training Time = 0.52 seconds\n",
      "Epoch 24 - Training loss: 0.01711004763543606\n",
      "\n",
      "Training Time = 0.59 seconds\n",
      "Epoch 25 - Training loss: 0.016097929087281224\n",
      "\n",
      "Training Time = 0.55 seconds\n",
      "Number Of Images Tested = 2000\n",
      "\n",
      "Model Accuracy = 0.9395 \n",
      "\n",
      "\n",
      "Number Of Inequalities tested = 1000\n",
      "\n",
      "Model Accuracy = 0.952\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# WITH BATCHES\n",
    "\n",
    "\n",
    "model = Net_convo()\n",
    "\n",
    "criterion1 = nn.NLLLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.8)\n",
    "epochs = 25\n",
    "\n",
    "mini_batch_size = 25\n",
    "\n",
    "for e in range(epochs):\n",
    "    time0 = time()\n",
    "    running_loss = 0\n",
    "    for b in range(0, train_input.size(0), mini_batch_size):\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = model(train_input.narrow(0, b, mini_batch_size))\n",
    "        \n",
    "        loss1 = criterion1(output1.view(-1, 10), train_classes.narrow(0, b, mini_batch_size).view(-1))\n",
    "        loss2 = criterion2(output2.view(-1), train_target.narrow(0, b, mini_batch_size).to(torch.float32))\n",
    "\n",
    "        w2 = 0.6\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        running_loss += loss1.item() + loss2.item() * w2\n",
    "\n",
    "    print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(train_input)))\n",
    "    print(\"\\nTraining Time =\", round(time()-time0, 2), \"seconds\")\n",
    "compute_err_digit_recog(model, test_input, test_classes, batches = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
