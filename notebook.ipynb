{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import *\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(\n",
    "    500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "print(train_input.narrow(0, 4, 20).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_norm = (train_input - torch.min(train_input)) / (torch.max(train_input))\n",
    "test_input_norm = (test_input - torch.min(train_input)) / (torch.max(train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21916c3ea90>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMhElEQVR4nO3df+xddX3H8efLFqitkFI3GLTEYsJQwtxwDb90bLMaKzBK4v6AjKX+GN2SbYIx0zKSGf9bojGaSSSIKJEGliBOwtTRgY5tEUaBhl8FqcigUCkMQQajpfDeH9/bpHxpobnn3NMrn+cj+ebec+/5fN/v701fOT/uOf2kqpD0xvemfd2ApGEYdqkRhl1qhGGXGmHYpUbMHbLY/jmg5rFgyJJSU17gObbXtuzuvUHDPo8FnJDlQ5aUmnJL3bDH99yNlxph2KVGGHapEZ3CnmRFkvuTbEqypq+mJPVv7LAnmQNcBHwIOAY4O8kxfTUmqV9dtuzHA5uq6sGq2g5cBazspy1JfesS9sXAI7ssbx699gpJVidZn2T9i2zrUE5SF13Cvrsv7l91v2xVXVJVy6pq2X4c0KGcpC66hH0zcMQuy0uAx7q1I2lSuoT9VuCoJEcm2R84C7i2n7Yk9W3sy2WrakeSvwL+BZgDXFZV9/TWmaRedbo2vqq+B3yvp14kTZBX0EmNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSI7rM4npEkh8m2ZjkniTn9dmYpH51+X/jdwCfqqrbkxwI3JZkXVXd21Nvkno09pa9qrZU1e2j588CG9nNLK6SpkOnGWF2SrIUOA64ZTfvrQZWA8xjfh/lJI2h8wm6JG8Bvg2cX1W/nP2+UzZL06FT2JPsx0zQ11bVNf20JGkSupyND/B1YGNVfbG/liRNQpct+3uAPwXel2TD6OfUnvqS1LMu87P/B5Aee5E0QV5BJzXCsEuN6OV7dr22J1ef1Gn8CefeMfbYDy+6tVPt9857odP4z2393bHHXnXXsk61f/Pce8YeW9u2dao9jdyyS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjvMV1L73wR8ePPfaiNV/pVPujt31k7LH3/t1vdao978Y7O40/5danxx774Psv61T75DP/YuyxB/7jzZ1qTyO37FIjDLvUCMMuNcKwS43oY/qnOUnuSHJdHw1Jmow+tuznMTODq6Qp1nWutyXAacCl/bQjaVK6btm/BHwaeHlPKyRZnWR9kvUv8sb773mlXxVdJnY8HdhaVbe91npO2SxNh64TO56R5CHgKmYmeLyil64k9W7ssFfVBVW1pKqWAmcBN1bVOb11JqlXfs8uNaKXG2Gq6kfAj/r4XZImwy271AjDLjXC+9n30tbjxv+o5mVHp9pLV/107LEvP/98p9rVaTRcdtfJY4/92z+8v1PthbdvHXvsS50qTye37FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCG9x3UvpcM/j2+Z2u2HyTYsOHnts11tcu0q63iTbweNP7rvaU8gtu9QIwy41wrBLjTDsUiO6Tuy4MMnVSe5LsjHJSX01JqlfXc/Gfxn4QVX9cZL9gfk99CRpAsYOe5KDgFOAjwBU1XZgez9tSepbl934twNPAN9IckeSS5MsmL2SUzZL06FL2OcC7wa+WlXHAc8Ba2av5JTN0nToEvbNwOaqumW0fDUz4Zc0hbpM2fxz4JEkR49eWg7c20tXknrX9Wz8XwNrR2fiHwQ+2r0lSZPQKexVtQFY1lMvkibIK+ikRhh2qRHez76Xll5839hjn/vzlzvVXvbPD4099j/PP6FT7Rfeul+n8V874Wtjj92wrdt1GS93HP9G45ZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGeD/7Xnrpf54ae+yHL/ybTrUXn7tp7LH/uvayTrX3pXMe+mCn8bXt6Z46eWNwyy41wrBLjTDsUiO6Ttn8yST3JLk7yZVJ5vXVmKR+jR32JIuBTwDLqupYYA5wVl+NSepX1934ucCbk8xlZm72x7q3JGkSusz19ijwBeBhYAvwTFVdP3s9p2yWpkOX3fiDgZXAkcDhwIIk58xezymbpenQZTf+/cDPquqJqnoRuAY4uZ+2JPWtS9gfBk5MMj9JmJmyeWM/bUnqW5dj9luAq4HbgbtGv+uSnvqS1LOuUzZ/FvhsT71ImiCvoJMaYdilRniL6wAWfuvHncY/d0XGHnva4ad2qv3SYYs6jT/kHx4ee+x//ds7O9U+km6f+xuNW3apEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxrh/ey/CqrGHrrj0W7zdsx5/v86jf+zQ28ae+y//8ZRnWrrldyyS40w7FIjDLvUiNcNe5LLkmxNcvcury1Ksi7JA6PHgyfbpqSu9mbL/k1gxazX1gA3VNVRwA2jZUlT7HXDXlU3AU/NenklcPno+eXAmT33Jaln4x6zH1pVWwBGj4fsaUWnbJamw8RP0DllszQdxg3740kOAxg9bu2vJUmTMG7YrwVWjZ6vAr7bTzuSJmVvvnq7EvgxcHSSzUk+Dvw98IEkDwAfGC1LmmKve218VZ29h7eW99yLpAnyCjqpEYZdaoS3uOo1vfSLX3Qaf9P/vmP8wTX+VNV6NbfsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wvvZNVEbnlky9tj9F2zvsRO5ZZcaYdilRhh2qRHjTtn8+ST3JbkzyXeSLJxsm5K6GnfK5nXAsVX1LuAnwAU99yWpZ2NN2VxV11fVjtHizcD4p1wlDaKPY/aPAd/v4fdImqBO37MnuRDYAax9jXVWA6sB5jG/SzlJHYwd9iSrgNOB5VVVe1qvqi4BLgE4KIv2uJ6kyRor7ElWAJ8Bfr+qnu+3JUmTMO6UzV8BDgTWJdmQ5OIJ9ympo3GnbP76BHqRNEFeQSc1wrBLjfAWV03Us7/35NhjlzL+WL2aW3apEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxph2KVGGHapEYZdaoRhlxqR1/iPYfsvljwB/PdrrPJrsM9uYra2td8Itd9WVb++uzcGDfvrSbK+qpZZ29rW7p+78VIjDLvUiGkL+yXWtra1J2OqjtklTc60bdklTYhhlxoxFWFPsiLJ/Uk2JVkzYN0jkvwwycYk9yQ5b6jau/QwJ8kdSa4buO7CJFcnuW/09580YO1Pjj7vu5NcmWTehOtdlmRrkrt3eW1RknVJHhg9Hjxg7c+PPvc7k3wnycJJ1J5tn4c9yRzgIuBDwDHA2UmOGaj8DuBTVfVO4ETgLwesvdN5wMaBawJ8GfhBVb0D+O2hekiyGPgEsKyqjgXmAGdNuOw3gRWzXlsD3FBVRwE3jJaHqr0OOLaq3gX8BLhgQrVfYZ+HHTge2FRVD1bVduAqYOUQhatqS1XdPnr+LDP/4BcPURsgyRLgNODSoWqO6h4EnMJogs6q2l5VTw/YwlzgzUnmAvOBxyZZrKpuAp6a9fJK4PLR88uBM4eqXVXXV9WO0eLNwJJJ1J5tGsK+GHhkl+XNDBi4nZIsBY4Dbhmw7JeATwMvD1gT4O3AE8A3RocQlyZZMEThqnoU+ALwMLAFeKaqrh+i9iyHVtWWUU9bgEP2QQ8AHwO+P0ShaQh7dvPaoN8HJnkL8G3g/Kr65UA1Twe2VtVtQ9SbZS7wbuCrVXUc8ByT2419hdGx8UrgSOBwYEGSc4aoPW2SXMjMoeTaIepNQ9g3A0fssryECe/W7SrJfswEfW1VXTNUXeA9wBlJHmLm0OV9Sa4YqPZmYHNV7dyLuZqZ8A/h/cDPquqJqnoRuAY4eaDau3o8yWEAo8etQxZPsgo4HfiTGuhil2kI+63AUUmOTLI/Mydrrh2icJIwc9y6saq+OETNnarqgqpaUlVLmfmbb6yqQbZwVfVz4JEkR49eWg7cO0RtZnbfT0wyf/T5L2ffnKC8Flg1er4K+O5QhZOsAD4DnFFVzw9Vl6ra5z/AqcyclfwpcOGAdd/LzCHDncCG0c+p++Dv/wPguoFr/g6wfvS3/xNw8IC1PwfcB9wNfAs4YML1rmTm/MCLzOzVfBx4KzNn4R8YPS4asPYmZs5T7fw3d/EQn7uXy0qNmIbdeEkDMOxSIwy71AjDLjXCsEuNMOxSIwy71Ij/B/hOkdvw2gGPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_input_norm[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35893\n"
     ]
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "print(get_n_params(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7186, -3.7186, -3.7186, -3.7186, -3.7186, -3.7186, -3.6163, -1.2753,\n",
      "         -3.7186, -0.6465],\n",
      "        [-2.4163, -2.4163, -2.4163, -2.4163, -2.4163, -2.4163, -2.4163, -2.4163,\n",
      "         -2.4163, -1.6258]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([[0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0243, 0.0269, 0.2794, 0.0243,\n",
      "         0.5239],\n",
      "        [0.0892, 0.0892, 0.0892, 0.0892, 0.0892, 0.0892, 0.0892, 0.0892, 0.0892,\n",
      "         0.1968]], grad_fn=<ExpBackward>)\n",
      "LogSoftmax(dim=tensor([ 2.0000,  1.0000,  0.5000,  0.1000, -1.0000, -1.5000, -2.4000]))\n"
     ]
    }
   ],
   "source": [
    "print(output1)\n",
    "print(torch.exp(output1))\n",
    "a = [2, 1, 0.5, 0.1, -1, -1.5, -2.4]\n",
    "print(nn.LogSoftmax(torch.Tensor(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 2.9942418920993803\n",
      "\n",
      "Training Time (in minutes) = 0.015981630484263102\n",
      "Epoch 2 - Training loss: 2.975035026550293\n",
      "\n",
      "Training Time (in minutes) = 0.036864463488260904\n",
      "Epoch 3 - Training loss: 2.8800882954001428\n",
      "\n",
      "Training Time (in minutes) = 0.05512582063674927\n",
      "Epoch 4 - Training loss: 2.7762050319314002\n",
      "\n",
      "Training Time (in minutes) = 0.07206240892410279\n",
      "Epoch 5 - Training loss: 2.5650940282046797\n",
      "\n",
      "Training Time (in minutes) = 0.09012586673100789\n",
      "Epoch 6 - Training loss: 2.2537725726626814\n",
      "\n",
      "Training Time (in minutes) = 0.10738617579142253\n",
      "Epoch 7 - Training loss: 1.7636218709377571\n",
      "\n",
      "Training Time (in minutes) = 0.12409043709437052\n",
      "Epoch 8 - Training loss: 1.3699749893380795\n",
      "\n",
      "Training Time (in minutes) = 0.14210370381673176\n",
      "Epoch 9 - Training loss: 1.1777798128723806\n",
      "\n",
      "Training Time (in minutes) = 0.1584065596262614\n",
      "Epoch 10 - Training loss: 1.0621644876176632\n",
      "\n",
      "Training Time (in minutes) = 0.17510500351587932\n",
      "Epoch 11 - Training loss: 0.9623489315116549\n",
      "\n",
      "Training Time (in minutes) = 0.1926133354504903\n",
      "Epoch 12 - Training loss: 0.9206402475065797\n",
      "\n",
      "Training Time (in minutes) = 0.21050761540730795\n",
      "Epoch 13 - Training loss: 0.8658563555679785\n",
      "\n",
      "Training Time (in minutes) = 0.2294665813446045\n",
      "Epoch 14 - Training loss: 0.8471853546355614\n",
      "\n",
      "Training Time (in minutes) = 0.24727521340052286\n",
      "Epoch 15 - Training loss: 0.8022895848598178\n",
      "\n",
      "Training Time (in minutes) = 0.26374527215957644\n",
      "Epoch 16 - Training loss: 0.7777023547387496\n",
      "\n",
      "Training Time (in minutes) = 0.280167822043101\n",
      "Epoch 17 - Training loss: 0.6792352963667556\n",
      "\n",
      "Training Time (in minutes) = 0.29784555435180665\n",
      "Epoch 18 - Training loss: 0.4882108673557142\n",
      "\n",
      "Training Time (in minutes) = 0.3144216736157735\n",
      "Epoch 19 - Training loss: 0.38596740209385827\n",
      "\n",
      "Training Time (in minutes) = 0.3328650633494059\n",
      "Epoch 20 - Training loss: 0.374715157739581\n",
      "\n",
      "Training Time (in minutes) = 0.35096627473831177\n",
      "Epoch 21 - Training loss: 0.25883415439732377\n",
      "\n",
      "Training Time (in minutes) = 0.36977174679438274\n",
      "Epoch 22 - Training loss: 0.2084243987422187\n",
      "\n",
      "Training Time (in minutes) = 0.38697824080785115\n",
      "Epoch 23 - Training loss: 0.16629471435129448\n",
      "\n",
      "Training Time (in minutes) = 0.4040925860404968\n",
      "Epoch 24 - Training loss: 0.20360659208459345\n",
      "\n",
      "Training Time (in minutes) = 0.4220235824584961\n",
      "Epoch 25 - Training loss: 0.13651259884955744\n",
      "\n",
      "Training Time (in minutes) = 0.43907284339269004\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(196, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "        self.fc5 = nn.Linear(20, 1)\n",
    "        \n",
    "        self.logsoft = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # INPUT IS A (2, 14, 14) TENSOR, OUTPUT IS (1)\n",
    "        x = self.fc0(x)\n",
    "        # (2, 196)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        output1 = self.logsoft(x)\n",
    "        #x = F.relu(self.fc5(torch.exp(x)))\n",
    "        #print(x.size())\n",
    "        x = torch.flatten(x, 0)\n",
    "        #print(x.size())\n",
    "        output2 = self.fc5(x)\n",
    "        #print(output2)\n",
    "        return output1, output2\n",
    "\n",
    "model = Net2()\n",
    "\n",
    "criterion1 = nn.NLLLoss()\n",
    "criterion2 = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 25\n",
    "\n",
    "#train_input_flat = torch.flatten(train_input_norm, 0, 1)\n",
    "#train_classes_flat = torch.flatten(train_classes, 0, 1)\n",
    "mini_batch_size = 25\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for i in range(len(train_input_norm)):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #optimizer_aux.zero_grad()\n",
    "        #print(torch.flatten(train_input_flat.narrow(0, b, mini_batch_size), 1, 2).size())\n",
    "        \n",
    "        output1, output2 = model(train_input_norm[i])\n",
    "        \n",
    "        loss1 = criterion1(output1, train_classes[i])\n",
    "        loss2 = criterion2(output2, train_target[i].reshape(1).to(torch.float32))\n",
    "        #print(loss2)\n",
    "        \n",
    "        loss = loss1 + loss2 * 0.15\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        running_loss += loss1.item() + loss2.item()\n",
    "    \n",
    "    print(\"Epoch {} - Training loss: {}\".format(e+1, running_loss/len(train_input)))\n",
    "    print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 1000\n",
      "\n",
      "Model Accuracy = 0.891\n",
      "Number Of Images Tested = 500\n",
      "\n",
      "Model Accuracy = 0.429\n"
     ]
    }
   ],
   "source": [
    "def compute_err_digit_recog(model, test_input_norm, test_classes): # CHANGER LES NOMS SVP\n",
    "\n",
    "    correct_count_digit, all_count_digit = 0, 0\n",
    "    correct_count_equal, all_count_equal = 0, 0\n",
    "    \n",
    "    for img, label, target, i in zip(test_input_norm, test_classes, test_target, range(len(test_classes))):   \n",
    "\n",
    "        with torch.no_grad():\n",
    "            log_probs_digits, probs_equality = model(img)\n",
    "        \n",
    "        #print(torch.sigmoid(probs_equality), test_target[i])\n",
    "\n",
    "\n",
    "        probs = torch.exp(log_probs_digits)\n",
    "        _, preds = torch.max(probs,dim=1)\n",
    "        true_labels = test_classes[i]\n",
    "\n",
    "        for predicted, groundtruth in zip(preds, true_labels):\n",
    "            if(predicted == groundtruth):\n",
    "                correct_count_digit += 1\n",
    "            all_count_digit += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        if((torch.sigmoid(probs_equality) >= 0.5 and test_target[i] == 1) or (torch.sigmoid(probs_equality) < 0.5 and test_target[i] == 0)):\n",
    "            correct_count_equal += 1\n",
    "        all_count_equal +=1\n",
    "        \n",
    "\n",
    "    print(\"Number Of Images Tested =\", all_count_digit)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count_digit/all_count))\n",
    "    print(\"Number Of Images Tested =\", all_count_equal)\n",
    "    print(\"\\nModel Accuracy =\", (correct_count_equal/all_count))\n",
    "    \n",
    "compute_err_digit_recog(model, test_input_norm, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 2, 14, 14])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (25x392 and 196x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a9d81039a807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcompute_nb_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-a9d81039a807>\u001b[0m in \u001b[0;36mcompute_nb_errors\u001b[0;34m(model, data_input, data_target, mini_batch_size)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-da5469f09605>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# (2, 196)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1690\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (25x392 and 196x128)"
     ]
    }
   ],
   "source": [
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    correct_count, all_count = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        _, output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        for k in range(mini_batch_size):\n",
    "            print(data_target[b+k])\n",
    "            print(predicted_classes[k])\n",
    "            print(\"|----|\")\n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors\n",
    "\n",
    "print(train_input.size())\n",
    "\n",
    "compute_nb_errors(model, train_input, train_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(test_classes_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196])\n"
     ]
    }
   ],
   "source": [
    "print(torch.flatten(torch.flatten(test_input_norm, 0, 1), 1, 2).size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
